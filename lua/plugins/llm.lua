return {
  -- 'huggingface/llm.nvim',
  -- opts = {
  --   backend = 'ollama',
  --   url = 'http://localhost:11434', -- llm-ls uses "/api/generate"
  --   model = 'qwen2.5-coder:0.5b',
  --   accept_keymap = "<M-l>",
  --   context_window = 32768,
  --   tokenizer = {
  --     repository = 'Qwen/Qwen2.5-Coder-0.5B',
  --   },
  -- },
}
